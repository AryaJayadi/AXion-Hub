---
phase: 01-foundation-infrastructure
plan: 07
type: execute
wave: 4
depends_on:
  - 01-02
  - 01-03
files_modified:
  - src/features/audit/lib/middleware.ts
  - src/features/audit/lib/hash.ts
  - src/features/audit/index.ts
  - src/shared/lib/queue.ts
  - workers/audit-worker.ts
  - workers/index.ts
  - app/api/health/route.ts
  - app/api/audit/test/route.ts
autonomous: true
requirements:
  - INFR-10
  - INFR-11

must_haves:
  truths:
    - "A mutating API endpoint automatically creates an audit log entry in the database with actor, action, resource, before/after diffs, and metadata"
    - "Audit log entries are hash-chained for tamper detection (each entry references the previous entry's hash)"
    - "BullMQ audit queue processes audit log entries asynchronously via a worker"
    - "The health endpoint returns the status of PostgreSQL and Redis connections"
    - "BullMQ worker runs as a separate process, not embedded in Next.js API routes"
  artifacts:
    - path: "src/features/audit/lib/middleware.ts"
      provides: "Audit logging middleware for API routes"
      exports: ["createAuditLog", "withAudit"]
      min_lines: 40
    - path: "src/features/audit/lib/hash.ts"
      provides: "Hash chain computation for tamper detection"
      exports: ["computeAuditHash"]
    - path: "src/shared/lib/queue.ts"
      provides: "BullMQ queue instances"
      exports: ["auditQueue"]
    - path: "workers/audit-worker.ts"
      provides: "BullMQ audit worker process"
      contains: "Worker"
      min_lines: 30
    - path: "app/api/health/route.ts"
      provides: "Health check endpoint"
      exports: ["GET"]
    - path: "app/api/audit/test/route.ts"
      provides: "Test endpoint demonstrating audit middleware"
      exports: ["POST"]
  key_links:
    - from: "src/features/audit/lib/middleware.ts"
      to: "src/shared/lib/queue.ts"
      via: "enqueues audit job"
      pattern: "auditQueue\\.add"
    - from: "workers/audit-worker.ts"
      to: "src/shared/lib/db.ts"
      via: "inserts audit record into database"
      pattern: "db\\.insert.*auditLogs"
    - from: "src/features/audit/lib/hash.ts"
      to: "workers/audit-worker.ts"
      via: "called during audit record creation"
      pattern: "computeAuditHash"
    - from: "app/api/audit/test/route.ts"
      to: "src/features/audit/lib/middleware.ts"
      via: "uses audit middleware"
      pattern: "createAuditLog|withAudit"
---

<objective>
Build the audit logging middleware that automatically records mutations in API endpoints, the BullMQ job queue for async processing, the audit hash chain for tamper detection, a health check endpoint, and a test endpoint to verify the full audit pipeline.

Purpose: Audit logging is baked into every mutating API endpoint from the start. Processing audit records asynchronously via BullMQ prevents audit logging from slowing down API responses. The hash chain makes the audit log tamper-evident.
Output: Working audit middleware, BullMQ queue + worker, health endpoint, and verified end-to-end audit pipeline.
</objective>

<execution_context>
@/home/arya/.claude/get-shit-done/workflows/execute-plan.md
@/home/arya/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation-infrastructure/01-RESEARCH.md
@.planning/phases/01-foundation-infrastructure/01-01-SUMMARY.md
@.planning/phases/01-foundation-infrastructure/01-02-SUMMARY.md
@.planning/phases/01-foundation-infrastructure/01-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create audit logging middleware, hash chain, and BullMQ queue setup</name>
  <files>
    src/features/audit/lib/middleware.ts
    src/features/audit/lib/hash.ts
    src/features/audit/index.ts
    src/shared/lib/queue.ts
  </files>
  <action>
    1. Create `src/shared/lib/queue.ts` with BullMQ queue instances:
       ```typescript
       import { Queue } from 'bullmq';
       import { createRedisConnection } from './redis';

       // Each queue needs its own Redis connection
       export const auditQueue = new Queue('audit', {
         connection: createRedisConnection(),
         defaultJobOptions: {
           removeOnComplete: { count: 1000 },  // Keep last 1000 completed jobs
           removeOnFail: { count: 5000 },       // Keep last 5000 failed jobs
           attempts: 3,
           backoff: { type: 'exponential', delay: 1000 },
         },
       });

       // Future queues (placeholder comments):
       // export const workflowQueue = new Queue('workflow', { connection: createRedisConnection() });
       // export const notificationQueue = new Queue('notification', { connection: createRedisConnection() });
       ```

    2. Create `src/features/audit/lib/hash.ts` for tamper detection:
       ```typescript
       import { createHash } from 'node:crypto';

       interface AuditHashInput {
         timestamp: Date;
         actor: string;
         action: string;
         resourceType: string;
         resourceId: string;
         before: unknown;
         after: unknown;
         prevHash: string | null;
       }

       export function computeAuditHash(input: AuditHashInput): string {
         const data = JSON.stringify({
           timestamp: input.timestamp.toISOString(),
           actor: input.actor,
           action: input.action,
           resourceType: input.resourceType,
           resourceId: input.resourceId,
           before: input.before,
           after: input.after,
           prevHash: input.prevHash,
         });
         return createHash('sha256').update(data).digest('hex');
       }
       ```

    3. Create `src/features/audit/lib/middleware.ts` (per RESEARCH.md Pattern 7):

       **createAuditLog function:** Accepts an AuditContext and enqueues a job to the audit queue:
       ```typescript
       type AuditContext = {
         actor: string;
         actorType: 'user' | 'system' | 'webhook';
         action: 'create' | 'update' | 'delete';
         resourceType: string;
         resourceId: string;
         before?: unknown;
         after?: unknown;
       };

       export async function createAuditLog(ctx: AuditContext, request?: Request): Promise<void> {
         const metadata = request ? {
           ip: request.headers.get('x-forwarded-for') || request.headers.get('x-real-ip') || 'unknown',
           userAgent: request.headers.get('user-agent') || 'unknown',
           correlationId: nanoid(),
           url: request.url,
           method: request.method,
         } : { correlationId: nanoid() };

         // Scrub secrets from before/after
         const sanitizedBefore = scrubSecrets(ctx.before);
         const sanitizedAfter = scrubSecrets(ctx.after);

         // Enqueue to BullMQ for async processing
         await auditQueue.add('audit-log', {
           ...ctx,
           before: sanitizedBefore,
           after: sanitizedAfter,
           metadata,
           timestamp: new Date().toISOString(),
         });
       }
       ```

       **withAudit higher-order function:** Wraps a Next.js API route handler to add audit logging:
       ```typescript
       type RouteHandler = (request: Request) => Promise<Response>;

       interface AuditOptions {
         action: 'create' | 'update' | 'delete';
         resourceType: string;
         getResourceId: (request: Request, response: Response) => string | Promise<string>;
         getBefore?: (request: Request) => unknown | Promise<unknown>;
         getAfter?: (request: Request, response: Response) => unknown | Promise<unknown>;
       }

       export function withAudit(handler: RouteHandler, options: AuditOptions): RouteHandler {
         return async (request: Request) => {
           const before = options.getBefore ? await options.getBefore(request) : undefined;
           const response = await handler(request);

           // Only audit successful mutations
           if (response.ok) {
             const after = options.getAfter ? await options.getAfter(request, response) : undefined;
             const resourceId = await options.getResourceId(request, response);

             await createAuditLog({
               actor: 'system', // Will be replaced with auth user in Phase 2
               actorType: 'system',
               action: options.action,
               resourceType: options.resourceType,
               resourceId,
               before,
               after,
             }, request);
           }

           return response;
         };
       }
       ```

       **scrubSecrets function:** Recursively scrubs sensitive keys from objects:
       - Sensitive key patterns: password, api_key, apiKey, token, secret, authorization
       - Replaces values with '[REDACTED]'
       - Handles nested objects (one level deep to avoid infinite recursion)

    4. Update `src/features/audit/index.ts` to export the full public API:
       - Re-export: createAuditLog, withAudit, computeAuditHash, auditLogs (schema)
  </action>
  <verify>
    - TypeScript compiles all new files without errors
    - `createAuditLog` function can be imported and called (enqueues job)
    - `withAudit` function wraps a route handler correctly
    - `computeAuditHash` produces consistent hashes for the same input
    - `scrubSecrets` redacts password/token/secret fields
  </verify>
  <done>
    Audit middleware created with createAuditLog (direct) and withAudit (HOC) APIs. Secret scrubbing prevents sensitive data in audit logs. Hash chain function ready for tamper detection. BullMQ audit queue configured with retry policy.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create BullMQ audit worker, health endpoint, and test the full audit pipeline</name>
  <files>
    workers/audit-worker.ts
    workers/index.ts
    app/api/health/route.ts
    app/api/audit/test/route.ts
    docker-compose.yml
  </files>
  <action>
    1. Create `workers/audit-worker.ts` (per RESEARCH.md BullMQ pattern):

       **Worker process:**
       ```typescript
       import { Worker } from 'bullmq';
       import { db } from '../src/shared/lib/db';
       import { auditLogs } from '../src/features/audit/model/schema';
       import { computeAuditHash } from '../src/features/audit/lib/hash';
       import { createRedisConnection } from '../src/shared/lib/redis';
       import { desc, eq } from 'drizzle-orm';

       const connection = createRedisConnection();

       const auditWorker = new Worker(
         'audit',
         async (job) => {
           const { actor, actorType, action, resourceType, resourceId, before, after, metadata, timestamp } = job.data;

           // Get the previous audit log's hash for chain
           const [lastLog] = await db.select({ prevHash: auditLogs.prevHash, id: auditLogs.id })
             .from(auditLogs)
             .orderBy(desc(auditLogs.id))
             .limit(1);

           const prevHash = lastLog?.prevHash ?? null;

           // Compute hash for this record
           const hash = computeAuditHash({
             timestamp: new Date(timestamp),
             actor,
             action,
             resourceType,
             resourceId,
             before,
             after,
             prevHash,
           });

           // Insert into database
           await db.insert(auditLogs).values({
             timestamp: new Date(timestamp),
             actor,
             actorType,
             action,
             resourceType,
             resourceId,
             before,
             after,
             metadata,
             prevHash: hash,
           });
         },
         {
           connection,
           concurrency: 5,
         }
       );

       // Logging
       auditWorker.on('completed', (job) => {
         console.log(`[audit-worker] Job ${job.id} completed`);
       });

       auditWorker.on('failed', (job, err) => {
         console.error(`[audit-worker] Job ${job?.id} failed:`, err.message);
       });

       console.log('[audit-worker] Started, waiting for jobs...');
       ```

    2. Create `workers/index.ts` as the worker entry point:
       ```typescript
       // Import all workers -- they self-register on import
       import './audit-worker';

       console.log('[workers] All workers initialized');
       ```

    3. Add a worker service to `docker-compose.yml`:
       ```yaml
       worker:
         build:
           context: .
           dockerfile: Dockerfile
           target: dev
         command: ["bun", "run", "workers/index.ts"]
         environment:
           DATABASE_URL: postgres://axion:axion@db:5432/axion
           REDIS_URL: redis://redis:6379
         depends_on:
           db:
             condition: service_healthy
           redis:
             condition: service_healthy
         volumes:
           - .:/app
           - /app/node_modules
       ```
       NOTE: The worker runs as a SEPARATE service in Docker, not inside the Next.js app. It shares the same codebase via bind mount but runs `workers/index.ts` instead of `next dev`.

    4. Add a `worker` script to `package.json`:
       ```json
       "worker": "bun run workers/index.ts"
       ```

    5. Create `app/api/health/route.ts`:
       ```typescript
       import { pool } from '@/shared/lib/db';
       import { redis } from '@/shared/lib/redis';

       export async function GET() {
         const checks: Record<string, 'ok' | 'error'> = {};

         // PostgreSQL check
         try {
           const client = await pool.connect();
           await client.query('SELECT 1');
           client.release();
           checks.database = 'ok';
         } catch {
           checks.database = 'error';
         }

         // Redis check
         try {
           const pong = await redis.ping();
           checks.redis = pong === 'PONG' ? 'ok' : 'error';
         } catch {
           checks.redis = 'error';
         }

         const allHealthy = Object.values(checks).every(v => v === 'ok');

         return Response.json(
           { status: allHealthy ? 'healthy' : 'degraded', checks, timestamp: new Date().toISOString() },
           { status: allHealthy ? 200 : 503 }
         );
       }
       ```

    6. Create `app/api/audit/test/route.ts` -- a test endpoint that demonstrates the audit middleware:
       ```typescript
       import { createAuditLog } from '@/features/audit';

       export async function POST(request: Request) {
         const body = await request.json();

         // Simulate a resource creation
         const resourceId = `test-${Date.now()}`;

         // Log the audit event
         await createAuditLog({
           actor: 'system',
           actorType: 'system',
           action: 'create',
           resourceType: 'test-resource',
           resourceId,
           after: body,
         }, request);

         return Response.json({ id: resourceId, message: 'Test resource created, audit log queued' }, { status: 201 });
       }
       ```

    7. Verify the full pipeline end-to-end:
       - Start Docker: `docker compose up -d` (includes the worker service now)
       - Wait for health: `curl http://localhost:3000/api/health` should show database: ok, redis: ok
       - Create test audit log: `curl -X POST http://localhost:3000/api/audit/test -H "Content-Type: application/json" -d '{"name":"test","value":42}'`
       - Wait 2 seconds for BullMQ to process
       - Query database: `docker compose exec db psql -U axion -d axion -c "SELECT id, actor, action, resource_type, resource_id, prev_hash FROM audit_logs ORDER BY id DESC LIMIT 5"`
       - Verify the audit record exists with correct data

    NOTE: This test endpoint (`/api/audit/test`) is for Phase 1 verification only. It can be removed or protected in later phases.
  </action>
  <verify>
    - `docker compose up -d` starts all services including the worker
    - `curl http://localhost:3000/api/health` returns `{"status":"healthy","checks":{"database":"ok","redis":"ok"}}`
    - `curl -X POST http://localhost:3000/api/audit/test -H "Content-Type: application/json" -d '{"name":"test"}'` returns 201
    - After 2s: `docker compose exec db psql -U axion -d axion -c "SELECT count(*) FROM audit_logs"` shows 1+ records
    - Worker logs show "Job completed" messages: `docker compose logs worker`
    - Hash chain: records have non-null prev_hash values
  </verify>
  <done>
    Full audit pipeline works end-to-end: API endpoint calls createAuditLog, job is enqueued to BullMQ, worker picks it up, computes hash chain, inserts into PostgreSQL. Health endpoint reports database and Redis status. Worker runs as a separate Docker service. The audit infrastructure is ready for all mutating API endpoints in subsequent phases.
  </done>
</task>

</tasks>

<verification>
1. Health endpoint returns database: ok, redis: ok
2. POST to /api/audit/test creates an audit log entry
3. BullMQ worker processes the audit job within seconds
4. Audit record in database has correct actor, action, resource fields
5. Audit record has non-null prev_hash (hash chain working)
6. Secret scrubbing redacts sensitive fields in before/after diffs
7. Worker runs as a separate Docker Compose service
8. Worker handles errors gracefully (failed jobs are retried)
</verification>

<success_criteria>
- createAuditLog enqueues audit jobs to BullMQ
- withAudit HOC wraps route handlers to auto-audit mutations
- BullMQ worker processes audit jobs and inserts records with hash chain
- Health endpoint checks PostgreSQL and Redis connectivity
- Test endpoint demonstrates the full audit pipeline
- Worker runs separately from Next.js (not in API routes)
- All audit records have tamper-detection hashes
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-infrastructure/01-07-SUMMARY.md`
</output>
